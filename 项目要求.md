# 期末Project：大模型生成文本内容识别

## 作业概述

- 主题：期末作业——大模型生成文本内容识别
- 任务定位：构建二分类模型，区分人类撰写文本（学生作文）与LLM 生成文本，推动 AI 内容检测技术落地
- 核心目标：基于真实学生作文与多模型生成文本的混合数据集，训练高精度分类器，输出文本为AI 生成的概率值

## 数据格式与特征

数据集结构

- 输入文件：
    - train.jsonl/test.jsonl：包含文本 ID、写作提示ID、文本内容、标签（训练集，generated=0.0为人写，1.0为 AI 生成）
    - train_prompts.jsonl：写作提示示例（含标题、指导语、源文本Markdown 格式，部分带作者/ 子标题）

关键特征：

- 源文本包含段落编号、标题格式（# 标题/## 子标题），部分无作者信息，需模型捕捉人工写作与AI 生成的细微差异

数据规模：

- 训练集与测试集包含多LLM 生成文本（如GPT-4、LLaMA-2、文心一言等），覆盖多样化写作场景

## 核心任务要求

预测目标：

- 对测试集每条样本，输出generated概率值（0.0~1.0），表示文本为AI 生成的可能性

输出格式：

- 严格遵循JSONL 格式，使用指定函数保存结果：
- `def saveJsonl(filePath: str, datas: list) -> None: # 代码逻辑见文档段落7-16`

数据领取：

- 通过百度网盘链接获取数据集，包含训练/ 测试数据及提示示例
    - https://pan.baidu.com/s/1i2Q7QgdchfJMOdLghwgWaw?pwd=t4hg
    - 提取码:t4hg
- 鼓励大家自行扩充训练集，即自行添加ai生成的例子

## 评分标准

核心指标：

- ROC-AUC：衡量模型区分人写与AI 生成文本的整体能力，值越接近1 性能越优

评估逻辑：

- 基于预测概率计算受试者工作特征曲线下面积，关注模型在不同阈值下的分类均衡性

## 基线方法与模型示例

基线模型：BERT 二分类器：

- 输入处理：将文本内容拼接为[CLS]文本内容[SEP]格式，保留Markdown 结构（如段落编号、标题）
- 模型结构：
    - BERT 编码器提取CLS 向量，接两层MLP 分类头（768→256→2），输出Softmax概率
    - 包含Dropout（0.3）和BatchNorm层，缓解过拟合

优化方向：

- 可引入文本特征工程（如n-gram 频率、标点符号分布）、预训练模型微调（如RoBERTa、
GPT-Neo）或集成学习（Stacking）

## 提交规范与注意事项

交付物：

- 分类结果文件（test_pred.jsonl），每行一个样本，包含id和generated概率值

关键提示：

- 确保代码可复现：训练流程需包含数据加载、预处理（如Markdown 解析）、模型训练与预测
- 避免过度依赖基线：鼓励探索AI 生成文本的特有模式（如重复短语、逻辑结构规律性）

分类任务：⼤模型⽣成⽂本内容识别

## ⼀、问题背景

近年来，⼤型语⾔模型（LLMs）技术⽇益精密，其⽣成的⽂本已愈发难以与⼈类创作的内容区分。本任务旨在推动开放研究与技术透明，重点关注可适⽤于现实场景的AI内容检测技术开发。

本次竞赛要求参赛者构建能够精准判别⽂本来源的机器学习模型⸺即准确识别所给⽂章是出⾃学⽣之⼿，还是由⼈⼯智能⽣成。本任务数据集由真实学⽣作⽂与各类LLMs（包括多种主流模型）⽣成的⽂本混合组成，为模型训练与验证提供多维度挑战。

## ⼆、数据格式

1. {train|test}.jsonl
    - id - 唯⼀作⽂标识符
    - prompt_id - 对应的写作提示编号
    - text - 作⽂⽂本内容
    - generated - 标识⽂章为学⽣撰写（0.0）或由LLM⽣成（1.0）。该字段为⽬标变量，测试集中不提供。
2. train_prompts.jsonl，注意，该部分数据只给出部分写作提示充当示例，实际训练集与测试集并不局限于该⽂件包含的写作提示。
    - prompt_id - 唯⼀提示编号
    - prompt_name - 提示标题
    - instructions - 给予学⽣的写作指导
    - source_text - 以Markdown格式存储的源⽂本（学⽣需基于此撰写作⽂），包含以下特征：
        - 重要段落前标注数字编号（如 0 第⼀段内容\n\n1 第⼆段内容）
        - ⽂章标题以 # 标题 格式标注，若存在作者则显示为 # 作者：姓名
        - 可能包含⼦标题（## ⼦标题格式）
        - 部分⽂章未标注作者

## 三、具体要求

1. 对测试集中的每条样本的进⾏⼤模型⽣成⽂本内容识别，要求给出每条样本判定为⼤模型⽣成内容的概率值。每条样本的分类结果按以下格式存储：
    
    ```python
    {"id":"e_pnbrb0gj", "generated": 0.9}
    ```
    
    样本分类结果的列表请使⽤如下代码保存：
    
    ```python
    def saveJsonl(filePath: str, datas: list) -> None:
    	assert isinstance(datas, list), "datas should be a list"
    	directory = os.path.dirname(filePath)
    	if directory and not os.path.exists(directory):
    		os.makedirs(directory)
    	try:
    		with open(filePath, 'w', encoding='utf-8') as f:
    		for data in datas:
    		f.write(json.dumps(data, ensure_ascii=False) + '\n')
    	except IOError as e:
    		print(f"Error writing to file {filePath}: {e}")
    ```
    
2. 将分类结果的`.jsonl`⽂件提交，由助教负责计算结果、评分。
3. 数据领取：通过⽹盘分享的⽂件：PJ_aidetect 链接:
https://pan.baidu.com/s/1i2Q7QgdchfJMOdLghwgWaw?pwd=t4hg 提取码: t4hg

## 四、评分标准

模型提交结果的评分基于预测概率与真实标签之间的受试者⼯作特征曲线下⾯积（ROC-AUC）。该指标通过计算模型预测概率与观测⽬标值的分类性能，衡量模型区分⼈类创作⽂本与AI⽣成⽂本的能⼒。ROC曲线下⾯积（AUC值）越接近1，表示模型的⼆分类性能越优。

## 五、Baseline（供参考）

使⽤Bert做情感分类，处理输⼊为：

```python
"[CLS]Dear TEACHER_NAME,\n\nI believe that cell phone policy should be a
one day use because i have seen students take there time on the phones and
not do any work. Students just waste time when they don't need to be doing
so. I also think if you allow them too bring in their cells its going to
make kids want to spend more of ther time playing with their phones
instead of listening or focusing what teachers are saying. Some other
reasons why is cause some people will abuse this by bringing drugs and
making it look like something else for example: A pencil case which has
drugs in it but looks like a regular item from store. Another reason would
be a student trying to cheat off another person who happens to have a
phone so he or she can get help on whatever they need without the teacher
knowing about it. Also students wouldn't show respect towards
adults.\n\nThese are all my reasons as to why having your phone out during
class shouldn't happen unless for an emergency call or texting parents for
permission to go somewhere outside of school for instance.[SEP]",
```

然后输⼊Bert，接⼊⼆分类头：

```python
class BertClassifier(nn.Module):
	def __init__(self, bert_path: str, hidden_size=768, mid_size=256):
		super(BertClassifier, self).__init__()
		# bert
		self.bert = BertModel.from_pretrained(bert_path)
		# dropout
		self.dropout = nn.Dropout(0.3)
		# MLP: 768->256->5
		self.classifier = nn.Sequential(
			nn.Linear(hidden_size, mid_size),
			nn.BatchNorm1d(mid_size),
			nn.ReLU(),
			nn.Dropout(0.5),
			nn.Linear(mid_size, 2),
		)

	def forward(self, x):
		# input_ids
		context = x[0]
		# token_type_ids
		types = x[1]
		# attention_mask
		mask = x[2]
		
		# pooled,就是cls的向量
		_, pooled = self.bert(context, token_type_ids=types,
							attention_mask=mask,
							output_all_encoded_layers=False)
		
        # 正则化
		context_embedding = self.dropout(pooled)
		
        # 分类头，输出logits
		output = self.classifier(context_embedding)
		# softmax转换概率
		output = F.softmax(output, dim=1)
		return output
```