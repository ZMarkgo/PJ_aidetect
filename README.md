# 大模型生成文本内容识别

这个项目旨在构建一个二分类模型，用于区分人类撰写的文本（学生作文）与LLM生成的文本。

## 项目概述

- **任务定位**：构建二分类模型，区分人类撰写文本与LLM生成文本
- **核心目标**：基于真实学生作文与多模型生成文本的混合数据集，训练高精度分类器，输出文本为AI生成的概率值
- **评价指标**：ROC-AUC（受试者工作特征曲线下面积）

## 数据集说明

数据集包含以下文件：

- `train.jsonl` - 训练数据集，包含文本ID、写作提示ID、文本内容和标签
- `test.jsonl` - 测试数据集，包含文本ID、写作提示ID和文本内容
- `train_prompts.jsonl` - 写作提示示例

数据格式：
- `id` - 唯一作文标识符
- `prompt_id` - 对应的写作提示编号
- `text` - 作文文本内容
- `generated` - 标识文章为学生撰写（0.0）或由LLM生成（1.0）

## 项目结构

项目包含以下主要文件：

- `ai_detect.py` - 主要实现文件，基于BERT的文本分类器
- `ml_ai_detect.py` - 基于传统机器学习的轻量级实现
- `data_analyzer.py` - 数据集分析工具
- `requirements.txt` - 项目依赖
- `README.md` - 项目说明文档

## 特征工程

本项目采用了以下特征：

1. **文本语义特征**：使用BERT模型提取文本的语义表示
2. **统计特征**：
   - 文本长度
   - 句子数量和平均长度
   - 标点符号使用比例
   - 大写字母比例
   - 词汇多样性比例
   - Markdown格式特征（标题、子标题、数字编号）
   - 重复词语比例
   - 行数和特殊字符比例

## 模型架构

### 1. 基于BERT的深度学习模型 (`ai_detect.py`)

- **编码器**：BERT-base-uncased
- **特征融合**：结合BERT输出和手工特征
- **分类器**：MLP分类头
- **训练技巧**：早停、模型选择

### 2. 传统机器学习模型 (`ml_ai_detect.py`)

- **特征提取**：TF-IDF向量化和统计特征
- **基础模型**：梯度提升树和随机森林
- **融合方法**：逻辑回归元分类器

## 使用方法

### 环境配置

```bash
pip install -r requirements.txt
```

### 数据分析

```bash
python data_analyzer.py
```

### 模型训练与预测

1. BERT模型（推荐）：

```bash
python ai_detect.py
```

2. 传统机器学习模型（轻量级）：

```bash
python ml_ai_detect.py
```

生成的预测结果将保存为`test_pred.jsonl`或`test_pred_ml.jsonl`文件。

## 结果分析

通过特征工程和模型优化，我们在验证集上实现了较高的AUC得分。关键发现：

1. 人类撰写的文本和AI生成的文本在语法、句子长度分布、词汇多样性等方面存在差异
2. 结合语义和统计特征能够显著提高模型性能
3. 特殊格式和标记（如Markdown格式）的使用模式也是区分两类文本的重要特征

## 优化策略

为提高模型性能，我们采用了以下策略：

1. **特征工程**：提取语言学特征和格式特征
2. **模型融合**：结合多个模型的预测结果
3. **超参数优化**：调整模型参数以获得最佳性能
4. **交叉验证**：使用交叉验证确保模型稳定性

## 待改进方向

1. 尝试更多的预训练模型（如RoBERTa、ALBERT等）
2. 探索更多文本特征（如情感极性、句法复杂度等）
3. 实现更复杂的模型融合策略（如堆叠集成）
4. 对不同类型的LLM生成文本进行特定优化 