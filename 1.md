# 大模型生成文本内容识别实验报告

## 一、模型设计

### 1.1 BERT模型
- 采用BERT（bert-base-uncased）作为主干模型，提取文本语义特征。
- 使用[CLS]向量表示整体语义，作为分类基础。
- 引入统计类人工特征：
  - 文本长度（归一化到5000）
  - 句子数量（归一化到200）
  - 平均句子长度（归一化到100）
  - 标点符号比例
  - 大写字母比例
  - 词汇多样性比例
  - Markdown格式特征（标题、子标题）
  - 数字编号特征
- 模型架构：
  - BERT编码器：提取文本语义表示（输出维度768）
  - Dropout层（0.3）：防止过拟合
  - 特征融合层：将9维手工特征映射到256维空间
  - 组合层：融合BERT输出（768维）和手工特征（256维）
  - 分类头：
    - 256维全连接层
    - BatchNorm1d
    - ReLU激活
    - Dropout（0.5）
    - 1维输出层
    - Sigmoid激活
- 训练策略：
  - 优化器：AdamW
  - 学习率：2e-5（默认）或1e-5（可选）
  - 损失函数：二元交叉熵（Binary Cross Entropy）
  - 批次大小：训练8，评估16
  - 最大序列长度：512
  - 评估指标：可选准确率（acc）或AUC
  - 模型保存：保存验证集性能最佳的模型

### 1.2 传统机器学习模型
- 特征工程：
  - TF-IDF特征：
    - 最大特征数：5000
    - n-gram范围：1-2
    - 停用词：英文
    - 最小文档频率：5
  - 统计特征：
    - 文本长度、句子数量和平均长度、句子长度标准差
    - 标点符号比例、大写字母比例
    - 词汇多样性比例、平均词长
    - 重复词语比例
    - Markdown格式特征（标题、子标题）
    - 数字编号特征
    - 行数和特殊字符比例
- 模型架构：
  - TF-IDF特征模型：梯度提升树
    - 决策树数量：200
    - 学习率：0.1
    - 最大深度：5
  - 统计特征模型：随机森林
    - 决策树数量：100
    - 最大深度：10
  - 模型融合：逻辑回归
    - 输入：TF-IDF模型和统计特征模型的预测概率
    - 输出：最终预测概率

## 二、数据处理

- 输入数据为JSONL格式，包含字段 `text` 与 `generated`。
- 使用BERT自带分词器进行分词处理。
- 提取Markdown结构信息，如标题、子标题、编号等格式性特征。
- 保持标签平衡，划分90%训练集，10%验证集。

## 三、训练与优化

### 3.1 BERT模型
- 训练流程：
  1. 数据预处理：
     - 文本分词和编码
     - 手工特征提取和归一化
  2. 模型训练：
     - 支持断点续训（通过--resume参数）
     - 每个epoch在验证集上评估
     - 保存验证集性能最佳的模型
  3. 预测：
     - 使用保存的最佳模型进行预测
     - 输出生成概率（0-1之间）
- 优化策略：
  - 使用Dropout防止过拟合（BERT层0.3，分类头0.5）
  - 特征归一化处理
  - 支持学习率调整
  - 支持不同评估指标（准确率/AUC）

### 3.2 传统机器学习模型
- 训练流程：
  1. 首先训练TF-IDF特征模型，使用梯度提升树
  2. 然后训练统计特征模型，使用随机森林
  3. 最后使用逻辑回归融合两个模型的预测结果
- 评估方式：
  - 分别评估TF-IDF特征模型和统计特征模型的AUC
  - 评估融合模型在验证集上的AUC
- 预测流程：
  1. 使用TF-IDF模型和统计特征模型分别预测概率
  2. 将两个模型的预测概率拼接
  3. 使用逻辑回归模型输出最终预测概率

## 四、预测与输出

- 对测试集文本逐条处理，模型输出generated字段的概率值。
- 结果以JSONL格式写入 `test_pred.jsonl`，包含 `id` 与 `score` 字段。

## 五、结果与分析

### 5.1 模型性能对比

1. BERT模型：
   - 验证集AUC：0.9521（3轮）和0.9605（9轮）
   - 测试集得分：88.32（3轮）和86.98（9轮）

2. 传统机器学习模型：
   - TF-IDF特征AUC：0.8240
   - 统计特征AUC：0.8131
   - 融合模型AUC：0.8668
   - 测试集得分：77.50

### 5.2 结果分析

1. 模型性能比较：
   - BERT模型在验证集和测试集上都取得了更好的性能，说明深度学习模型在捕捉文本语义特征方面具有优势
   - 传统机器学习模型虽然性能略低，但训练速度快，资源消耗小

2. 特征重要性：
   - TF-IDF特征（AUC: 0.8240）比统计特征（AUC: 0.8131）表现更好，说明词汇使用模式是区分AI生成文本的重要指标
   - 特征融合后性能提升（AUC: 0.8668），证明多特征组合的有效性

3. 训练策略影响：
   - BERT模型在3轮训练时达到最佳测试集性能（88.32），而9轮训练虽然验证集AUC更高（0.9605），但测试集性能反而下降（86.98）
   - 这种现象表明模型在9轮训练时出现了过拟合：模型在训练数据上表现越来越好，但泛化能力下降
   - 传统机器学习模型通过特征工程和模型融合，在轻量级方案中取得了不错的效果

4. 过拟合分析：
   - BERT模型在9轮训练时验证集AUC达到0.9605，但测试集性能下降，说明模型过度拟合了训练数据的特征
   - 3轮训练时模型在验证集和测试集上的表现更加平衡，说明较短的训练轮数可能更适合当前任务
   - 建议采用以下策略缓解过拟合：
     - 增加Dropout率
     - 使用更多的数据增强
     - 实现学习率衰减
     - 采用交叉验证选择最佳训练轮数

# 分工

- 张文擘
  - 数据分布分析
  - 模型优化
- 唐润泽
  - 数据处理
- 欧闻毅
  - 代码实现
  - 模型设计
- 沈远哲
  - 模型训练
  - 结果分析
  - 模型设计
