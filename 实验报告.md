# 大模型生成文本内容识别实验报告

## 一、数据集分析

### 1.1 数据集概况
- 训练集：10000条样本
- 测试集：10000条样本
- 标签分布：
  - 人类撰写：6500条（65.00%）
  - AI生成：3500条（35.00%）

### 1.2 提示ID分布
- 训练集和测试集各有18种不同的提示ID
- 最常见的5个提示ID分布相似：
  - 提示ID 0：约8.9%
  - 提示ID 1：约8.6%
  - 提示ID 5：约7.8%
  - 提示ID 6：约7.4%
  - 提示ID 4：约7.2%

### 1.3 文本特征分析

#### 1.3.1 文本长度分布
![文本长度分布](results/text_length_distribution.png)
- 人类撰写文本平均长度：2343.89字符
- AI生成文本平均长度：2234.88字符
- 整体平均长度：2305.74字符
- 长度范围：275-16738字符
- 中位数：2064.50字符

#### 1.3.2 句子长度分布
![句子长度分布](results/sentence_length_distribution.png)
- AI生成文本平均句子长度：109.06字符
- 句子长度范围：1-4519字符
- 中位数：99.00字符

#### 1.3.3 标点符号使用
![标点符号使用分布](results/punctuation_ratio_distribution.png)
- AI生成文本标点符号比例：0.0160
- 整体标点符号比例：0.0160

#### 1.3.4 词汇多样性
![词汇多样性分布](results/word_uniqueness_distribution.png)
- AI生成文本词汇多样性：0.4851
- 整体词汇多样性：0.4851

#### 1.3.5 Markdown格式使用
- 标题使用：
  - 人类撰写：0.0000
  - AI生成：0.0003
- 子标题使用：
  - 人类撰写：0.0000
  - AI生成：0.0009
- 数字编号使用：
  - 人类撰写：0.0035
  - AI生成：0.0066

### 1.4 特征差异分析
1. 文本长度：
   - 人类撰写的文本平均长度略长于AI生成文本
   - 两种类型的文本长度分布较为接近

2. 句子结构：
   - AI生成文本的句子长度较为稳定，平均约109字符
   - 句子长度分布显示AI生成文本的句子结构更加规范

3. 标点符号使用：
   - 两种类型的文本标点符号使用比例较低
   - AI生成文本的标点使用更加规范

4. 词汇使用：
   - 词汇多样性约为0.4851，说明文本中约一半的词汇是重复的
   - AI生成文本的词汇使用更加规范

5. 格式特征：
   - Markdown格式使用率普遍较低
   - AI生成文本更倾向于使用结构化的格式（标题、子标题、编号）

## 二、模型设计

### 2.1 BERT模型
- 采用BERT（bert-base-uncased）作为主干模型，提取文本语义特征。
- 使用[CLS]向量表示整体语义，作为分类基础。
- 引入统计类人工特征：
  - 文本长度（归一化到5000）
  - 句子数量（归一化到200）
  - 平均句子长度（归一化到100）
  - 标点符号比例
  - 大写字母比例
  - 词汇多样性比例
  - Markdown格式特征（标题、子标题）
  - 数字编号特征
- 模型架构：
  - BERT编码器：提取文本语义表示（输出维度768）
  - Dropout层（0.3）：防止过拟合
  - 特征融合层：将9维手工特征映射到256维空间
  - 组合层：融合BERT输出（768维）和手工特征（256维）
  - 分类头：
    - 256维全连接层
    - BatchNorm1d
    - ReLU激活
    - Dropout（0.5）
    - 1维输出层
    - Sigmoid激活
- 训练策略：
  - 优化器：AdamW
  - 学习率：2e-5（默认）或1e-5（可选）
  - 损失函数：二元交叉熵（Binary Cross Entropy）
  - 批次大小：训练8，评估16
  - 最大序列长度：512
  - 评估指标：可选准确率（acc）或AUC
  - 模型保存：保存验证集性能最佳的模型

### 2.2 传统机器学习模型
- 特征工程：
  - TF-IDF特征：
    - 最大特征数：5000
    - n-gram范围：1-2
    - 停用词：英文
    - 最小文档频率：5
  - 统计特征：
    - 文本长度、句子数量和平均长度、句子长度标准差
    - 标点符号比例、大写字母比例
    - 词汇多样性比例、平均词长
    - 重复词语比例
    - Markdown格式特征（标题、子标题）
    - 数字编号特征
    - 行数和特殊字符比例
- 模型架构：
  - TF-IDF特征模型：梯度提升树
    - 决策树数量：200
    - 学习率：0.1
    - 最大深度：5
  - 统计特征模型：随机森林
    - 决策树数量：100
    - 最大深度：10
  - 模型融合：逻辑回归
    - 输入：TF-IDF模型和统计特征模型的预测概率
    - 输出：最终预测概率

## 三、数据处理

- 输入数据为JSONL格式，包含字段 `text` 与 `generated`。
- 使用BERT自带分词器进行分词处理。
- 提取Markdown结构信息，如标题、子标题、编号等格式性特征。
- 保持标签平衡，划分90%训练集，10%验证集。

## 四、训练与优化

### 4.1 BERT模型
- 训练流程：
  1. 数据预处理：
     - 文本分词和编码
     - 手工特征提取和归一化
  2. 模型训练：
     - 支持断点续训（通过--resume参数）
     - 每个epoch在验证集上评估
     - 保存验证集性能最佳的模型
  3. 预测：
     - 使用保存的最佳模型进行预测
     - 输出生成概率（0-1之间）
- 优化策略：
  - 使用Dropout防止过拟合（BERT层0.3，分类头0.5）
  - 特征归一化处理
  - 支持学习率调整
  - 支持不同评估指标（准确率/AUC）

### 4.2 传统机器学习模型
- 训练流程：
  1. 首先训练TF-IDF特征模型，使用梯度提升树
  2. 然后训练统计特征模型，使用随机森林
  3. 最后使用逻辑回归融合两个模型的预测结果
- 评估方式：
  - 分别评估TF-IDF特征模型和统计特征模型的AUC
  - 评估融合模型在验证集上的AUC
- 预测流程：
  1. 使用TF-IDF模型和统计特征模型分别预测概率
  2. 将两个模型的预测概率拼接
  3. 使用逻辑回归模型输出最终预测概率

## 五、预测与输出

- 对测试集文本逐条处理，模型输出generated字段的概率值。
- 结果以JSONL格式写入 `test_pred.jsonl`，包含 `id` 与 `score` 字段。

## 六、结果与分析

### 6.1 模型性能对比

1. BERT模型：
   - 验证集AUC：0.9521（3轮）和0.9605（9轮）
   - 测试集得分：88.32（3轮）和86.98（9轮）

2. 传统机器学习模型：
   - TF-IDF特征AUC：0.8240
   - 统计特征AUC：0.8131
   - 融合模型AUC：0.8668
   - 测试集得分：77.50

### 6.2 结果分析

1. 模型性能比较：
   - BERT模型在验证集和测试集上都取得了更好的性能，说明深度学习模型在捕捉文本语义特征方面具有优势
   - 传统机器学习模型虽然性能略低，但训练速度快，资源消耗小

2. 特征重要性：
   - TF-IDF特征（AUC: 0.8240）比统计特征（AUC: 0.8131）表现更好，说明词汇使用模式是区分AI生成文本的重要指标
   - 特征融合后性能提升（AUC: 0.8668），证明多特征组合的有效性

3. 训练策略影响：
   - BERT模型在3轮训练时达到最佳测试集性能（88.32），而9轮训练虽然验证集AUC更高（0.9605），但测试集性能反而下降（86.98）
   - 这种现象表明模型在9轮训练时出现了过拟合：模型在训练数据上表现越来越好，但泛化能力下降
   - 传统机器学习模型通过特征工程和模型融合，在轻量级方案中取得了不错的效果

4. 过拟合分析：
   - BERT模型在9轮训练时验证集AUC达到0.9605，但测试集性能下降，说明模型过度拟合了训练数据的特征
   - 3轮训练时模型在验证集和测试集上的表现更加平衡，说明较短的训练轮数可能更适合当前任务
   - 建议采用以下策略缓解过拟合：
     - 增加Dropout率
     - 使用更多的数据增强
     - 实现学习率衰减
     - 采用交叉验证选择最佳训练轮数

# 分工

- 张文擘
  - 数据分布分析
  - 模型优化
  - 报告撰写
- 唐润泽
  - 数据处理
- 欧闻毅
  - 代码实现
  - 模型设计
  - 报告撰写
- 沈远哲
  - 模型训练
  - 结果分析
  - 模型设计
